{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "### SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( Run <code>jupyter notebook</code> under the project directory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ppxgboost import BoosterParser as boostparser\n",
    "from ppxgboost import PPBooster as ppbooster\n",
    "from ppxgboost import PaillierAPI as paillier\n",
    "from ppxgboost.PPBooster import MetaData\n",
    "from ppxgboost.PPKey import PPBoostKey\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from secrets import token_bytes\n",
    "from pyope.ope import OPE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# XGBoost for Dataset\n",
    "\n",
    "This example demonstrates how to use ppxgboost to encrypt an xgboost model and query it.\n",
    "\n",
    "The sample dataset we are going to use in this lab is a sampled version of the \"Diabetes 130-US hospitals for years 1999-2008 Data Set\"  (Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014. ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Preparation and Train an XGBoost ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the following example, the datasets modified to match the input requirements by SageMaker Data Wrangler.\n",
    "data = pd.read_csv('../data/readmitted.csv')\n",
    "\n",
    "train, test = train_test_split(data, train_size = 0.998, test_size = 0.002)\n",
    "\n",
    "AttributeLabels = ['race', 'gender', 'age', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'max_glu_serum', 'a1c_result', 'change', 'diabetes_med']\n",
    "\n",
    "# Training dataset\n",
    "X_train = train[AttributeLabels]\n",
    "Y_train = train[['readmitted']]\n",
    "\n",
    "# Testing dataset\n",
    "X_test = test[AttributeLabels]\n",
    "Y_test = test[['readmitted']]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a xgboost model \n",
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "num_class = 3\n",
    "params = {'eta': 0.1, 'objective':'multi:softmax', 'num_class': num_class}\n",
    "model = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# predict using the plaintext prediction\n",
    "start = time.time()\n",
    "plaintext_predict = model.predict(xgb.DMatrix(X_test))\n",
    "end = time.time()\n",
    "print(\"XGBoost Prediction : Elapsed Time: \", end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Encryption Preparation for XGBoost Model\n",
    "\n",
    "1. Set up the encryption materials\n",
    "2. process the tree into ope_enc_tree\n",
    "3. Encrypts the input vector for prediction\n",
    "4. Perform the prediction\n",
    "5. Decrypt the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Booster Parser will parse the tree\n",
    "#  (add fake metadata here as this testing only test the model correctness)\n",
    "test_input_vector = pd.DataFrame(X_test)\n",
    "min_max = boostparser.training_dataset_parser(X_test)\n",
    "meta_min_max = MetaData(min_max)\n",
    "p_trees, features, min_max = boostparser.model_to_trees(model, min_max)\n",
    "\n",
    "# 1. Set up encryption materials.\n",
    "prf_key = token_bytes(16)\n",
    "public_key, private_key = paillier.he_key_gen()\n",
    "encrypter = OPE(token_bytes(16))\n",
    "ppBoostKey = PPBoostKey(public_key, prf_key, encrypter)\n",
    "\n",
    "# 2. process the tree into ope_enc_tree\n",
    "enc_trees = ppbooster.enc_xgboost_model(ppBoostKey, p_trees, meta_min_max)\n",
    "\n",
    "# 3. Encrypts the input vector for prediction (using prf_key_hash and ope-encrypter) based on the feature set.\n",
    "ppbooster.enc_input_vector(prf_key, encrypter, features, test_input_vector, meta_min_max)\n",
    "\n",
    "# # 4. OPE evaluation based on OPE encrypted values in the tree nodes.\n",
    "start = time.time()\n",
    "enc_predictions = ppbooster.predict_multiclass(enc_trees, num_class, test_input_vector)\n",
    "end = time.time()\n",
    "print(\"PPXGBoost Prediction : Elapsed Time: \", end - start)\n",
    "\n",
    "# 5. Client decryption.\n",
    "result = ppbooster.client_decrypt_prediction_multiclass(private_key, enc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result = np.array([round(x, 7) for x in result])\n",
    "assert len(plaintext_predict) == len(result)\n",
    "\n",
    "# check if the predicted values are same (the ppxgboost might not produce same values \n",
    "#                                    as the plaintext value due to precision)\n",
    "for i in range(len(plaintext_predict)):\n",
    "    assert abs(plaintext_predict[i] - result[i]) < 0.000001\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Jul  7 2022, 15:55:38) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "12397bf63e720d63033a49375741be539233a7bfd458c510a6e8607b9b1d305e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
