{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( Run <code>jupyter notebook</code> under the project directory )\n",
    "\n",
    "# XGBoost for Iris Dataset\n",
    "\n",
    "We use this example to demenstrate how to use ppxgboost for encypting an xgboost model for multi-class\n",
    " prediction. We directly use the iris data from Sklearn, but one\n",
    " can go to https://archive.ics.uci.edu/ml/datasets/iris to download the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from secrets import token_bytes\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ppxgboost import BoosterParser as boostparser\n",
    "from ppxgboost import PPBooster as ppbooster\n",
    "from ppxgboost.PPBooster import MetaData\n",
    "import ppxgboost.PPKey as PPKey\n",
    "import pyope.ope as pyope\n",
    "from ppxgboost import PaillierAPI as paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Pre-assign the column name first.\n",
    "# the default feature name from the xgboost -- iris have 4 columns\n",
    "feature_names = ['f0', 'f1', 'f2', 'f3']\n",
    "X = pd.DataFrame(X, columns=feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "test_input_vector = pd.DataFrame(X_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first dump and pickled the model in the file directory.\n",
    "# total number of tree = total_estimators * number_labels\n",
    "# e.g. for the imported iris dataset, the number of classes is 3.\n",
    "\n",
    "# Just provide estimator number for testing purposes.\n",
    "total_estimaters = 6\n",
    "model = xgb.XGBClassifier(n_estimators=total_estimaters, objective='multi:softmax')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of classes -- i.e. 3 from iris dataset\n",
    "# The classes as array can be get by calling model.classes_\n",
    "num_classes = model.n_classes_\n",
    "\n",
    "# Create custom data ranges\n",
    "in_range = pyope.ValueRange(pyope.DEFAULT_IN_RANGE_START, 2 ** 43 - 1)\n",
    "out_range = pyope.ValueRange(pyope.DEFAULT_OUT_RANGE_START, 2 ** 63 - 1)\n",
    "\n",
    "# Booster Parser will parse the tree\n",
    "#  (add fake metadata here as this testing only test the model correctness)\n",
    "min_max = {'min': 0, 'max': 100}\n",
    "meta_min_max = MetaData(min_max, in_range.end)\n",
    "p_trees, features, min_max = boostparser.model_to_trees(model.get_booster(), min_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Encryption Preparation for XGBoost Model\n",
    "1). Set up some metadata information for the dataset.\n",
    "2). Set up the encryption materials\n",
    "3). Encrypt the model\n",
    "4). Encrypt the query\n",
    "5). Perform the prediction \n",
    "6). Decrypt the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# # The folowing is to compute the scores based on the OPE processed decision tree #\n",
    "# ##################################################################################\n",
    "# # Set up encryption materials.\n",
    "ppModelKey, ppQueryKey = PPKey.generatePPXGBoostKeys()\n",
    "\n",
    "# 1. process the tree into ope_enc_tree\n",
    "enc_trees = ppbooster.enc_xgboost_model(ppModelKey, p_trees, meta_min_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encrypts the input vector for prediction (using prf_key_hash and ope-encrypter) based on the feature set.\n",
    "ppbooster.enc_input_vector(ppQueryKey.get_prf_key(), ppQueryKey.get_ope_encryptor(), features, test_input_vector, meta_min_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that: The prediction on the server side is done differently from the log:binary. This is because\n",
    "the server needs to perofrm the softmax aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. OPE evaluation based on OPE encrypted values in the tree nodes.\n",
    "enc_predictions = ppbooster.predict_multiclass(enc_trees, num_classes, test_input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Client decryption.\n",
    "result = ppbooster.client_decrypt_prediction_multiclass(ppQueryKey.get_private_key(), enc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y = model.predict(X_test)\n",
    "assert np.array_equal(result, real_y)\n",
    "print(\"success!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
